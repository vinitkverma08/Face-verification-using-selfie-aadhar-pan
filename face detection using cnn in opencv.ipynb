{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    " \n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt_path = r\"C:\\Users\\Vineet Kumar Verma\\Desktop\\Major Part - 1\\dataset_of_faces\\ResNet-10 prototxt file and caffe weights\\deploy.prototxt\"\n",
    "caffemodel_path = r\"C:\\Users\\Vineet Kumar Verma\\Desktop\\Major Part - 1\\dataset_of_faces\\ResNet-10 prototxt file and caffe weights\\res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces_using_opencv_cnn(src, dst, conf_threshold):\n",
    "    \n",
    "    count_undetected = 0\n",
    "    undetected_filename = []\n",
    "    \n",
    "    for path in glob.glob(os.path.join(src, '*.jpg')):\n",
    "        \n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        \n",
    "#         if (img.shape[0] > 1000):\n",
    "#             scale_percent = 50 # percent of original size\n",
    "#             width = int(img.shape[1] * scale_percent / 100)\n",
    "#             height = int(img.shape[0] * scale_percent / 100)\n",
    "#             dim = (width, height)\n",
    "#             img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        (frame_height, frame_width) = img.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1, (300, 300), (104.0, 177.0, 123.0), swapRB = True, crop = False)\n",
    "        model.setInput(blob)\n",
    "        detections = model.forward()\n",
    "        \n",
    "#         if detections.shape[2] == 0:\n",
    "#             img = rotate_bound(img, 90)\n",
    "#             (frame_height, frame_width) = img.shape[:2]\n",
    "#             blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1, (300, 300), (104.0, 177.0, 123.0), swapRB = True, crop = False)\n",
    "#             model.setInput(blob)\n",
    "#             detections = model.forward()\n",
    "        \n",
    "#         if detections.shape[2] == 0:\n",
    "#             img = rotate_bound(img, 90)\n",
    "#             (frame_height, frame_width) = img.shape[:2]\n",
    "#             blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1, (300, 300), (104.0, 177.0, 123.0), swapRB = True, crop = False)\n",
    "#             model.setInput(blob)\n",
    "#             detections = model.forward()\n",
    "        \n",
    "#         if detections.shape[2] == 0:\n",
    "#             img = rotate_bound(img, 90)\n",
    "#             (frame_height, frame_width) = img.shape[:2]\n",
    "#             blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1, (300, 300), (104.0, 177.0, 123.0), swapRB = True, crop = False)\n",
    "#             model.setInput(blob)\n",
    "#             detections = model.forward()\n",
    "        \n",
    "#         if detections.shape[2] == 0:\n",
    "#             count_undetected = count_undetected + 1\n",
    "#             undetected_filename.append(os.path.split(path)[1])\n",
    "        \n",
    "#         if (detections.shape[2] == 1 and confidence > conf_threshold):\n",
    "#             print(os.path.split(path)[1].split('.')[0], detections[0, 0, 0, 3:7])\n",
    "#             x1 = int(detections[0, 0, 0, 3] * frame_width)\n",
    "#             y1 = int(detections[0, 0, 0, 4] * frame_height)\n",
    "#             x2 = int(detections[0, 0, 0, 5] * frame_width)\n",
    "#             y2 = int(detections[0, 0, 0, 6] * frame_height)\n",
    "#             cv2.imwrite(os.path.join(dst, os.path.split(path)[1]), img[y1:y2, x1:x2])\n",
    "        \n",
    "#         if (detections.shape[2] == 1 and confidence < conf_threshold):\n",
    "#             count_undetected = count_undetected + 1\n",
    "#             undetected_filename.append(os.path.split(path)[1])\n",
    "        flag = 0\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > conf_threshold:\n",
    "                flag = 1\n",
    "                x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "                y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "                x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "                y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "                cv2.imwrite(os.path.join(dst, '{}-{}{}'.format(os.path.split(path)[1].split('.')[0], str(i+1), '.jpg')), img[y1:y2, x1:x2])\n",
    "        if flag == 0:\n",
    "            count_undetected = count_undetected + 1\n",
    "            undetected_filename.append(os.path.split(path)[1])\n",
    "                \n",
    "\n",
    "    print('Total undetected faces = {}'.format(count_undetected))\n",
    "    print('Faces from these images were not detected = {}'.format(undetected_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total undetected faces = 61\n",
      "Faces from these images were not detected = ['100.jpg', '11.jpg', '144.jpg', '145.jpg', '15.jpg', '165.jpg', '185.jpg', '190.jpg', '20.jpg', '22.jpg', '260.jpg', '267.jpg', '268.jpg', '27.jpg', '270.jpg', '276.jpg', '300.jpg', '303.jpg', '326.jpg', '38.jpg', '387.jpg', '391.jpg', '395.jpg', '40.jpg', '41.jpg', '42.jpg', '430.jpg', '44.jpg', '451.jpg', '46.jpg', '480.jpg', '50.jpg', '52.jpg', '53.jpg', '54.jpg', '555.jpg', '56.jpg', '561.jpg', '58.jpg', '583.jpg', '594.jpg', '60.jpg', '61.jpg', '63.jpg', '65.jpg', '67.jpg', '69.jpg', '71.jpg', '720.jpg', '73.jpg', '744.jpg', '750.jpg', '78.jpg', '791.jpg', '86.jpg', '87.jpg', '88.jpg', '90.jpg', '91.jpg', '97.jpg', '99.jpg']\n"
     ]
    }
   ],
   "source": [
    "aadhar_path = r\"C:\\Users\\Vineet Kumar Verma\\Desktop\\Major Part - 1\\dataset_of_faces\\RupeeGo Project\\Aadhar\"\n",
    "opencv_cnn_extracted_aadhar_path = \"C:/Users/Vineet Kumar Verma/Desktop/Major Part - 1/dataset_of_faces/Output of different models/Original Dataset/DNN detector in opencv/Aadhar/\"\n",
    "find_faces_using_opencv_cnn(aadhar_path, opencv_cnn_extracted_aadhar_path, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total undetected faces = 52\n",
      "Faces from these images were not detected = ['100.jpg', '11.jpg', '144.jpg', '145.jpg', '15.jpg', '150.jpg', '165.jpg', '173.jpg', '185.jpg', '190.jpg', '20.jpg', '22.jpg', '231.jpg', '267.jpg', '27.jpg', '276.jpg', '303.jpg', '307.jpg', '326.jpg', '38.jpg', '391.jpg', '395.jpg', '41.jpg', '44.jpg', '451.jpg', '46.jpg', '466.jpg', '480.jpg', '485.jpg', '50.jpg', '52.jpg', '54.jpg', '555.jpg', '567.jpg', '583.jpg', '594.jpg', '60.jpg', '63.jpg', '65.jpg', '67.jpg', '71.jpg', '720.jpg', '73.jpg', '744.jpg', '78.jpg', '787.jpg', '791.jpg', '88.jpg', '90.jpg', '91.jpg', '97.jpg', '99.jpg']\n"
     ]
    }
   ],
   "source": [
    "pan_path = r\"C:\\Users\\Vineet Kumar Verma\\Desktop\\Major Part - 1\\dataset_of_faces\\RupeeGo Project\\PAN\"\n",
    "opencv_cnn_extracted_pan_path = \"C:/Users/Vineet Kumar Verma/Desktop/Major Part - 1/dataset_of_faces/Output of different models/Original Dataset/DNN detector in opencv/PAN/\"\n",
    "find_faces_using_opencv_cnn(pan_path, opencv_cnn_extracted_pan_path, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total undetected faces = 5\n",
      "Faces from these images were not detected = ['145.jpg', '38.jpg', '46.jpg', '485.jpg', '63.jpg']\n"
     ]
    }
   ],
   "source": [
    "photo_path = r\"C:\\Users\\Vineet Kumar Verma\\Desktop\\Major Part - 1\\dataset_of_faces\\RupeeGo Project\\Photo\"\n",
    "opencv_cnn_extracted_photo_path = \"C:/Users/Vineet Kumar Verma/Desktop/Major Part - 1/dataset_of_faces/Output of different models/Original Dataset/DNN detector in opencv/Photo/\"\n",
    "find_faces_using_opencv_cnn(photo_path, opencv_cnn_extracted_photo_path, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
